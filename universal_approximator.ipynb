{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.nn.sequential import Sequential, EarlyStopping\n",
    "from utils.nn.layer import Dense\n",
    "from utils.nn.neuron import Activation\n",
    "from utils.nn.optimizer import Adam\n",
    "from utils.nn.losses import get_loss_function\n",
    "from utils.nn.initializer import Initializer, InitializationType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Function Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate Function 1\n",
    "\n",
    "**Let's use Multilayer Perceptron to learn approximation for this function on interval $[0, 15]$**\n",
    "\n",
    "$f(x) = -0.03 \\cdot x^2 \\cdot 0.05 \\cdot \\ln(x^3) + 0.5 \\cdot \\cos\\left(\\frac{x}{1.5}\\right) + 0.1 \\cdot \\sin(5x)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complicated_function(x):\n",
    "    return -0.03 * x**2  * 0.05 * np.log(x ** 3) + 0.5 * np.cos(x/1.5) + 0.1 * np.sin(x*5)\n",
    "\n",
    "def build_and_train_approximator():\n",
    "    \"\"\"Builds, trains, and evaluates a function approximator model.\"\"\"\n",
    "\n",
    "    # 1. Generate training data\n",
    "    x_values = np.linspace(0.1, 15, 200).reshape(-1, 1)\n",
    "    noise = np.random.normal(0, 0.05, x_values.shape)\n",
    "    y_values = complicated_function(x_values) + noise\n",
    "    \n",
    "    # 2. Define the model architecture\n",
    "    # FIX: Pass the shape tuple directly to the Dense layer.\n",
    "    # The Dense layer will correctly pass these dimensions to the Initializer.\n",
    "    model = Sequential([\n",
    "        Dense(shape=(1, 64), activation=Activation.RELU, initializer=Initializer(InitializationType.HE_UNIFORM, fan_in=1, fan_out=64)),\n",
    "        Dense(shape=(64, 64), activation=Activation.RELU, initializer=Initializer(InitializationType.HE_UNIFORM, fan_in=64, fan_out=64)),\n",
    "        Dense(shape=(64, 1), activation=Activation.LINEAR, initializer=Initializer(InitializationType.GLOROT_UNIFORM, fan_in=64, fan_out=1))\n",
    "    ])\n",
    "\n",
    "    # Print a summary of the model\n",
    "    model.summary()\n",
    "\n",
    "    # 3. Compile and train the model\n",
    "    optimizer = Adam(params=model.parameters(), learning_rate=0.001)\n",
    "    loss_function = get_loss_function('mse')\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=20, min_delta=0.0001, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        x_train=x_values,\n",
    "        y_train=y_values,\n",
    "        optimizer=optimizer,\n",
    "        loss_func=loss_function,\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        metric=\"r2_score\",\n",
    "        early_stopping=early_stopping,\n",
    "        display_interval=50\n",
    "    )\n",
    "\n",
    "    # 4. Evaluate and visualize the approximation\n",
    "    x_test = np.linspace(0.1, 15, 1000).reshape(-1, 1)\n",
    "    y_true = complicated_function(x_test)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    r2 = model.evaluate(x_test, y_true, metric_name=\"r2_score\")[1]\n",
    "    print(f\"\\nR2 Score on test data: {r2:.4f}\")\n",
    "    \n",
    "    # Visualization using Seaborn and Matplotlib\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot the original true function\n",
    "    sns.lineplot(x=x_test.flatten(), y=y_true.flatten(), color='blue', linewidth=3, label='True Function', zorder=10)\n",
    "\n",
    "    # Plot the noisy data points as a scatter plot\n",
    "    sns.scatterplot(x=x_values.flatten(), y=y_values.flatten(), color='red', alpha=0.5, label='Noisy Training Data', zorder=1)\n",
    "\n",
    "    # Plot the model's predictions\n",
    "    sns.lineplot(x=x_test.flatten(), y=y_pred.flatten(), color='green', linewidth=3, linestyle='--', label='MLP Approximation', zorder=5)\n",
    "\n",
    "    plt.title('Function Approximation using a Multilayer Perceptron', fontsize=18)\n",
    "    plt.xlabel('x', fontsize=14)\n",
    "    plt.ylabel('y', fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "    return x_test, y_true, y_pred\n",
    "\n",
    "build_and_train_approximator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate Function 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dampened_wave_function_2(x):\n",
    "    \"\"\"\n",
    "    A function that represents a dampened wave.\n",
    "    \"\"\"\n",
    "    return np.exp(-0.5 * x) * np.sin(x * 2)\n",
    "\n",
    "x_values_2 = np.linspace(0, 10, 200)  # Using more points for a smoother curve\n",
    "y_values_2 = dampened_wave_function_2(x_values_2)\n",
    "\n",
    "model_2 = Sequential(\n",
    "    layers=[\n",
    "        Dense(\n",
    "            shape=(1, 32),  # Increased neurons for more complexity\n",
    "            activation=Activation.TANH,\n",
    "            initializer=Initializer(fill_type=InitializationType.RANDOM_NORMAL)\n",
    "        ),\n",
    "        Dense(\n",
    "            shape=(32, 16),\n",
    "            activation=Activation.TANH,\n",
    "            initializer=Initializer(fill_type=InitializationType.RANDOM_NORMAL)\n",
    "        ),\n",
    "        Dense(\n",
    "            shape=(16, 16),\n",
    "            activation=Activation.RELU,\n",
    "            initializer=Initializer(fill_type=InitializationType.RANDOM_NORMAL)\n",
    "        ),\n",
    "        Dense(\n",
    "            shape=(16, 1),\n",
    "            activation=Activation.LINEAR,\n",
    "            initializer=Initializer(fill_type=InitializationType.RANDOM_NORMAL)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "approximator2 = FuncApproximator(\n",
    "    model=model_2,\n",
    "    scalar_func=dampened_wave_function_2,\n",
    "    x=x_values_2,\n",
    "    y=y_values_2\n",
    ")\n",
    "\n",
    "approximator2.fit(\n",
    "    batch_size=8,\n",
    "    test_split_size=0.15,\n",
    "    epochs=40,  # Increased epochs for better fitting\n",
    "    display_on_each_n_step=1,\n",
    "    learning_rate=0.005\n",
    ")\n",
    "\n",
    "approximator2.visualize_fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
