{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.nn.optimizer import Adam\n",
    "from utils.nn.neuron import Activation\n",
    "from utils.nn.layer import Dense, Dropout\n",
    "from utils.nn.sequential import Sequential\n",
    "from utils.nn.metrics import variables_to_float\n",
    "from utils.nn.losses import mean_squared_error_loss\n",
    "from utils.nn.initializer import Initializer, InitializationType\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Function Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuncApproximator:\n",
    "    \"\"\"\n",
    "    A class to approximate a scalar function using a FeedForward Neural Network.\n",
    "\n",
    "    Attributes:\n",
    "        model (FeedForwardNN): The neural network model to be trained.\n",
    "        scalar_func (callable): The function to be approximated.\n",
    "        x (np.ndarray): The input data points.\n",
    "        y (np.ndarray): The output data points corresponding to x.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: Sequential, scalar_func: callable, x: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        Initializes the FuncApproximator.\n",
    "\n",
    "        Args:\n",
    "            model (FeedForwardNN): An instance of the FeedForwardNN class.\n",
    "            scalar_func (callable): The scalar function to approximate.\n",
    "            x (np.ndarray): An array of input values.\n",
    "            y (np.ndarray): An array of output values from the scalar_func.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.scalar_func = scalar_func\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.y_pred = None  # To store predictions after fitting\n",
    "\n",
    "    def fit(self, batch_size: int, test_split_size: float, epochs: int, display_on_each_n_step: int, learning_rate: float = 0.001):\n",
    "        \"\"\"\n",
    "        Trains the neural network model to approximate the function.\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): The number of samples per batch.\n",
    "            test_split_size (float): The proportion of the dataset to include in the validation split.\n",
    "            epochs (int): The number of epochs to train for.\n",
    "            display_on_each_n_step (int): How often to display training progress.\n",
    "            learning_rate (float, optional): The learning rate for the optimizer. Defaults to 0.001.\n",
    "        \"\"\"\n",
    "        # Reshape data for train_test_split\n",
    "        X_data_reshaped = self.x.reshape(-1, 1)\n",
    "        self.y = self.y.reshape(-1, 1)#make it matrix\n",
    "\n",
    "        # Split data into training and validation sets\n",
    "        x_train_np, x_validate_np, y_train_np, y_validate_np = train_test_split(\n",
    "            X_data_reshaped, self.y, test_size=test_split_size, random_state=42\n",
    "        )\n",
    "\n",
    "        # Convert to list of lists for X and list for y, as expected by FeedForwardNN\n",
    "        x_train = x_train_np.tolist()\n",
    "        y_train = y_train_np.tolist()\n",
    "        x_validate = x_validate_np.tolist()\n",
    "        y_validate = y_validate_np.tolist()\n",
    "\n",
    "        # Choose Optimizer and Loss\n",
    "        params = self.model.parameters()\n",
    "        optimizer = Adam(params=params, learning_rate=learning_rate)\n",
    "        loss_fn = mean_squared_error_loss\n",
    "\n",
    "        # Fit the model\n",
    "        self.model.fit(\n",
    "            x_train=x_train,\n",
    "            y_train=y_train,\n",
    "            optimizer=optimizer,\n",
    "            loss_func=loss_fn,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            metric=\"mse\",\n",
    "            x_validate=x_validate,\n",
    "            y_validate=y_validate,\n",
    "            display_interval=display_on_each_n_step\n",
    "        )\n",
    "        \n",
    "        # After fitting, we can generate the predictions for visualization\n",
    "        self._predict_full_range()\n",
    "\n",
    "    def _predict_full_range(self):\n",
    "        \"\"\"Helper method to predict y values for the entire range of x.\"\"\"\n",
    "        X_full_for_prediction = [[val] for val in self.x]\n",
    "        y_pred_values_nested = self.model.forward_batch(x=X_full_for_prediction)\n",
    "        \n",
    "        # Extract the scalar value from the output\n",
    "        self.y_pred = np.array([val[0].value for val in y_pred_values_nested])\n",
    "\n",
    "\n",
    "    def visualize_fit(self):\n",
    "        \"\"\"\n",
    "        Visualizes the original function and the neural network's approximation.\n",
    "        \"\"\"\n",
    "        if self.y_pred is None:\n",
    "            print(\"Model has not been fitted yet. Please call the 'fit' method first.\")\n",
    "            return\n",
    "\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        plt.plot(self.x, self.y, label='True Function', color='blue', linewidth=2)\n",
    "        plt.plot(self.x, self.y_pred, label='NN Approximation', color='red', linestyle='--', alpha=0.7)\n",
    "        plt.title('Neural Network Approximation of a Function')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('f(x)')\n",
    "        plt.grid(True)\n",
    "        plt.legend(fontsize=12)\n",
    "        plt.axhline(0, color='black', linewidth=0.5)\n",
    "        plt.axvline(0, color='black', linewidth=0.5)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate Function 1\n",
    "\n",
    "**Let's use Multilayer Perceptron to learn approximation for this function on interval $[0, 15]$**\n",
    "\n",
    "$f(x) = -0.03 \\cdot x^2 \\cdot 0.05 \\cdot \\ln(x^3) + 0.5 \\cdot \\cos\\left(\\frac{x}{1.5}\\right) + 0.1 \\cdot \\sin(5x)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complicated_function(x):\n",
    "    return -0.03 * x**2  * 0.05 * np.log(x ** 3) + 0.5 * np.cos(x/1.5) + 0.1 * np.sin(x*5)\n",
    "\n",
    "x_values = np.linspace(0.1, 15, 100)\n",
    "y_values = complicated_function(x_values)\n",
    "\n",
    "model = Sequential(\n",
    "    layers=[\n",
    "        Dense(\n",
    "            shape=(1, 32),  # More neurons in the first layer\n",
    "            activation=Activation.TANH,\n",
    "            initializer=Initializer(fill_type=InitializationType.GLOROT_NORMAL) # Try Glorot\n",
    "        ),\n",
    "        Dense(\n",
    "            shape=(32, 16),\n",
    "            activation=Activation.RELU,\n",
    "            initializer=Initializer(fill_type=InitializationType.HE_NORMAL)\n",
    "        ),\n",
    "        Dense(\n",
    "            shape=(16, 16),\n",
    "            activation=Activation.RELU,\n",
    "            initializer=Initializer(fill_type=InitializationType.HE_NORMAL)\n",
    "        ),\n",
    "        Dropout(0.4, 16), # Slightly lower dropout rate, placed after a block\n",
    "        Dense(\n",
    "            shape=(16, 8),\n",
    "            activation=Activation.RELU,\n",
    "            initializer=Initializer(fill_type=InitializationType.HE_NORMAL)\n",
    "        ),\n",
    "        Dense(\n",
    "            shape=(8, 1),\n",
    "            activation=Activation.LINEAR,\n",
    "            initializer=Initializer(fill_type=InitializationType.HE_NORMAL)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "approximator1 = FuncApproximator(\n",
    "    model=model,\n",
    "    scalar_func=complicated_function,\n",
    "    x=x_values,\n",
    "    y=y_values\n",
    ")\n",
    "approximator1.fit(\n",
    "    batch_size=16,\n",
    "    test_split_size=0.1,\n",
    "    epochs=50,\n",
    "    display_on_each_n_step=5,\n",
    "    learning_rate=0.002\n",
    ")\n",
    "approximator1.visualize_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate Function 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dampened_wave_function_2(x):\n",
    "    \"\"\"\n",
    "    A function that represents a dampened wave.\n",
    "    \"\"\"\n",
    "    return np.exp(-0.5 * x) * np.sin(x * 2)\n",
    "\n",
    "x_values_2 = np.linspace(0, 10, 200)  # Using more points for a smoother curve\n",
    "y_values_2 = dampened_wave_function_2(x_values_2)\n",
    "\n",
    "model_2 = Sequential(\n",
    "    layers=[\n",
    "        Dense(\n",
    "            shape=(1, 32),  # Increased neurons for more complexity\n",
    "            activation=Activation.TANH,\n",
    "            initializer=Initializer(fill_type=InitializationType.RANDOM_NORMAL)\n",
    "        ),\n",
    "        Dense(\n",
    "            shape=(32, 16),\n",
    "            activation=Activation.TANH,\n",
    "            initializer=Initializer(fill_type=InitializationType.RANDOM_NORMAL)\n",
    "        ),\n",
    "        Dense(\n",
    "            shape=(16, 16),\n",
    "            activation=Activation.RELU,\n",
    "            initializer=Initializer(fill_type=InitializationType.RANDOM_NORMAL)\n",
    "        ),\n",
    "        Dense(\n",
    "            shape=(16, 1),\n",
    "            activation=Activation.LINEAR,\n",
    "            initializer=Initializer(fill_type=InitializationType.RANDOM_NORMAL)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "approximator2 = FuncApproximator(\n",
    "    model=model_2,\n",
    "    scalar_func=dampened_wave_function_2,\n",
    "    x=x_values_2,\n",
    "    y=y_values_2\n",
    ")\n",
    "\n",
    "approximator2.fit(\n",
    "    batch_size=8,\n",
    "    test_split_size=0.15,\n",
    "    epochs=40,  # Increased epochs for better fitting\n",
    "    display_on_each_n_step=1,\n",
    "    learning_rate=0.005\n",
    ")\n",
    "\n",
    "approximator2.visualize_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
