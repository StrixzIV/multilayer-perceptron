{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.nn.sequential import Sequential, EarlyStopping\n",
    "from utils.nn.layer import Dense, Dropout\n",
    "from utils.nn.neuron import Activation\n",
    "from utils.nn.optimizer import Adam\n",
    "from utils.nn.losses import get_loss_function\n",
    "from utils.nn.initializer import Initializer, InitializationType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Function Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_approximator(f, model, optimizer):\n",
    "\n",
    "    \"\"\"Builds, trains, and evaluates a function approximator model.\"\"\"\n",
    "\n",
    "    # 1. Generate training data\n",
    "    x_values = np.linspace(0.1, 15, 200).reshape(-1, 1)\n",
    "    noise = np.random.normal(0, 0.05, x_values.shape)\n",
    "    y_values = f(x_values) + noise\n",
    "\n",
    "    loss_function = get_loss_function('mse')    \n",
    "    early_stopping = EarlyStopping(patience=20, min_delta=0.0001, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        x_train=x_values,\n",
    "        y_train=y_values,\n",
    "        optimizer=optimizer,\n",
    "        loss_func=loss_function,\n",
    "        epochs=1000,\n",
    "        batch_size=64,\n",
    "        metric=\"r2_score\",\n",
    "        early_stopping=early_stopping,\n",
    "        display_interval=50\n",
    "    )\n",
    "\n",
    "    # 4. Evaluate and visualize the approximation\n",
    "    x_test = np.linspace(0.1, 15, 1000).reshape(-1, 1)\n",
    "    y_true = f(x_test)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    r2 = model.evaluate(x_test, y_true, metric_name=\"r2_score\")[1]\n",
    "    print(f\"\\nR2 Score on test data: {r2:.4f}\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot the original true function\n",
    "    sns.lineplot(x=x_test.flatten(), y=y_true.flatten(), color='blue', linewidth=3, label='True Function', zorder=10)\n",
    "\n",
    "    # Plot the noisy data points as a scatter plot\n",
    "    sns.scatterplot(x=x_values.flatten(), y=y_values.flatten(), color='red', alpha=0.5, label='Noisy Training Data', zorder=1)\n",
    "\n",
    "    # Plot the model's predictions\n",
    "    sns.lineplot(x=x_test.flatten(), y=y_pred.flatten(), color='green', linewidth=3, linestyle='--', label='MLP Approximation', zorder=5)\n",
    "\n",
    "    plt.title('Function Approximation using a Multilayer Perceptron', fontsize=18)\n",
    "    plt.xlabel('x', fontsize=14)\n",
    "    plt.ylabel('y', fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "    return x_test, y_true, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate Function 1\n",
    "\n",
    "$f(x) = -0.03 \\cdot x^2 \\cdot 0.05 \\cdot \\ln(x^3) + 0.5 \\cdot \\cos\\left(\\frac{x}{1.5}\\right) + 0.1 \\cdot \\sin(5x)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complicated_function(x):\n",
    "    return -0.03 * x**2  * 0.05 * np.log(x ** 3) + 0.5 * np.cos(x/1.5) + 0.1 * np.sin(x*5)\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "\tDense(shape=(1, 64), activation=Activation.SIGMOID, initializer=Initializer(InitializationType.GLOROT_UNIFORM, fan_in=1, fan_out=64)),\n",
    "\tDense(shape=(64, 64), activation=Activation.SIGMOID, initializer=Initializer(InitializationType.GLOROT_UNIFORM, fan_in=64, fan_out=64)),\n",
    "\tDense(shape=(64, 1), activation=Activation.LINEAR, initializer=Initializer(InitializationType.GLOROT_UNIFORM, fan_in=64, fan_out=1))\n",
    "])\n",
    "\n",
    "optimizer = Adam(params=model.parameters(), learning_rate=0.001)\n",
    "\n",
    "build_and_train_approximator(complicated_function, model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate Function 2\n",
    "\n",
    "$f(x) = e^{-0.5x}\\sin(2x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complicated_function(x):\n",
    "    \"\"\"\n",
    "    A function that represents a dampened wave.\n",
    "    \"\"\"\n",
    "    return np.exp(-0.5 * x) * np.sin(x * 2)\n",
    "\n",
    "model = Sequential([\n",
    "\tDense(\n",
    "\t\tshape=(1, 32),\n",
    "\t\tactivation=Activation.TANH,\n",
    "\t\tinitializer=Initializer(fill_type=InitializationType.GLOROT_UNIFORM, fan_in=1, fan_out=32)\n",
    "\t),\n",
    "\tDense(\n",
    "\t\tshape=(32, 16),\n",
    "\t\tactivation=Activation.TANH,\n",
    "\t\tinitializer=Initializer(fill_type=InitializationType.GLOROT_UNIFORM, fan_in=32, fan_out=16)\n",
    "\t),\n",
    "\tDense(\n",
    "\t\tshape=(16, 16),\n",
    "\t\tactivation=Activation.RELU,\n",
    "\t\tinitializer=Initializer(fill_type=InitializationType.GLOROT_UNIFORM, fan_in=16, fan_out=16)\n",
    "\t),\n",
    "\tDense(\n",
    "\t\tshape=(16, 1),\n",
    "\t\tactivation=Activation.LINEAR,\n",
    "\t\tinitializer=Initializer(fill_type=InitializationType.GLOROT_UNIFORM, fan_in=16, fan_out=1)\n",
    "\t)\n",
    "])\n",
    "\n",
    "optimizer = Adam(params=model.parameters(), learning_rate=0.001)\n",
    "\n",
    "build_and_train_approximator(complicated_function, model, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda310-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
